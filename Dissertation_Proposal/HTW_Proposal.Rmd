---
title: "Thomas Gorman Dissertation Proposal"
output: 
  rmdformats::readthedown:
    toc_depth: 2
csl: apa.csl
bibliography: "HTW.bib"
knit: (function(input_file, encoding) {
    out_dir <- 'docs';
    rmarkdown::render(input_file,
      encoding=encoding,
      output_file=file.path(dirname(input_file), out_dir, 'index.html'))})
editor_options: 
  markdown: 
    wrap: 72
---







```{r include = FALSE}
#my_citation <- cite_r(file = "r-references.bib")
options(tinytex.verbose = TRUE)
source('HTW_Prep_Paper_Data.R')
library(rmdformats)

chains = T
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(fig.pos = 'h')
```



## Project 2 {.tabset}

**Hit the Wall**

### Methods

[Participants]{.underline}

Data was collected from 647 participants (after exclusions). The results
shown below consider data from subjects in our initial experiment, which
consisted of 196 participants (106 constant, 90 varied). The follow-up
experiments entailed minor manipulations: 1) reversing the velocity
bands that were trained on vs. novel during testing; 2) providing
ordinal rather than numerical feedback during training (e.g. correct,
too low, too high). The data from these subsequent experiments are
largely consistently with our initial results shown below.

[Task]{.underline}

We developed a novel visuomotor extrapolation task, termed the ["Hit The
Wall" (HTW]{.underline}) task, wherein participants learned to launch a
projectile such that it hit a rectangle at the far end of the screen
with an appropriate amount of force. Although the projectile had both x
and y velocity components, only the x-dimension was relevant for the
task.

[Design:]{.underline}

1)  90 training trials split evenly divided between velocity bands.
    Varied training with 3 velocity bands and Constant training with 1
    band.

2)  No-feedback testing from 3 novel extrapolation bands. 15 trials
    each.  

3)  No-feedbacd testing from the 3 bands used during the training phase
    (2 of which were novel for the constant group). 9 trials each.

4)  Feedback testing for each of the 3 extrapolation bands. 10 trials
    each.

 

### Results {.tabset}

[Training:]{.underline}

Training performance is shown in Results Figure 2A. All groups show
improvement from each of their training velocity-bands (i.e. decreasing
average distance from target). In the velocity band trained at by both
groups (800-1000), the constant group maintains a superior level of
performance from the early through the final stages of training. This
difference is unsurprising given that the constant group had 3x more
practice trials from that band.

```{r Training, echo=FALSE,fig.height=4.0, fig.width=6}
#fig.cap="\\label{fig:figs}training performance"
nbins=8
dt%>% mutate(Trial.Bin=cut(trial,breaks=nbins,labels=FALSE)) %>%  
  group_by(sbjCode,condit,throwCategory,Trial.Bin) %>% summarise(dist=mean(dist),.groups = 'keep') %>%
   ggplot(aes(Trial.Bin,dist,color=throwCategory,group=throwCategory))+
  lineBars+
  facet_wrap(~condit)+
  scale_x_continuous(breaks=seq(1,nbins))+
  ylab("Mean Distance From Target Velocity")+xlab("Training Block")+
  scale_color_discrete(name="Velocity Band")+
  labs(title="Hit The Wall - Training Performance",
       caption="Figure 2A: Training Performance for both groups – binned into 8 blocks." )+
  theme(plot.caption=element_text(hjust=0,face="italic"))


```

[Testing:]{.underline}

Results Figure 2C shows the average velocity produced for all 6 bands
that were tested. At least at the aggregate level, both conditions were
able to differentiate all 6 bands in the correct order, despite only
having received training feedback for 1/6 (constant) or 3/6 (varied)
bands during training. Participants in both groups also had a bias
towards greatly overestimating the correct velocity for band 100-300,
for which both groups had an average of greater than 500.

```{r Testing Vx, echo=FALSE, fig.height=7, fig.width=9 }


sumStats = dtest %>% group_by(sbjCode,vbLabel,condit,throwCategory) %>%
  summarise(vxMean=mean(vxCapped),vxMedian=median(vxCapped),vxSd=sd(vxCapped),.groups = 'keep') %>%group_by(vbLabel,condit,throwCategory) %>%
  summarise(groupMean=round(mean(vxMean),0),groupMedian=round(mean(vxMedian),0),groupSd=round(mean(vxSd,na.rm=TRUE),0),.groups = 'keep') %>%
  mutate(meanLab=paste0("Mean=",groupMean),medianLab=paste0("Median=",groupMedian),sdLab=paste0("Sd=",groupSd)) %>%
  mutate(sumStatLab=paste0(meanLab,"\n",medianLab,"\n",sdLab))

fig2aCap=str_wrap("Figure 2B: Bands 100-300, 350-550 and 600-800 are novel extrapolations for both groups. Band 800-1000 was a training band for both groups. Bands 1000-1200, and 1200-1400 were trained for the varied group, and novel for the constant group.  Top figure displays mean deviation from correct velocity. Bottom figure displays the average % of trials where participants hit the wall with the correct velocity. Error bars indicate standard error of the mean. " ,width=200)

dtest %>% group_by(sbjCode,vbLabel,condit,throwCategory) %>%
  summarise(vxMean=mean(vxCapped),lowBound=first(bandInt),highBound=first(highBound),
            vbLag=first(vbLag),vbLead=first(vbLead),.groups = 'keep') %>%
  ggplot(aes(x=vbLabel,y=vxMean,fill=throwCategory))+
  geom_half_violin(color=NA)+ # remove border color
  geom_half_boxplot(position=position_nudge(x=-0.05),side="r",outlier.shape = NA,center=TRUE,
                    errorbar.draw = FALSE,width=.25)+
  geom_half_point(transformation = position_jitter(width = 0.05, height = 0.05),size=.3,aes(color=throwCategory))+
  facet_wrap(~condit,scale="free_x")+
  geom_rect(data=vbRect,aes(xmin=vbLag,xmax=vbLead,ymin=lowBound,ymax=highBound,fill=throwCategory),alpha=.3)+
  geom_text(data=sumStats,aes(y=2090,label = sumStatLab),size=2.5)+
  bandLines4+
  #geom_text(data=sumStats,aes(x=throwCategory,y=2100,label = groupMean),size=2, vjust = -0.5)+
  scale_y_continuous(expand=expansion(add=100),breaks=round(seq(0,2000,by=200),2))+
  scale_fill_discrete(name="Velocity Band")+
  scale_color_discrete(guide="none")+  # remove extra legend
  theme(legend.position='none',
        plot.title=element_text(face="bold"),
        axis.title.x=element_text(face="bold"),
        axis.title.y=element_text(face="bold"),
        axis.text.x = element_text(size = 7.5))+
  ylab("Mean X Velocity")+xlab("Target Velocity Band") +
   labs(title="Testing Performance (no-feedback) - X-Velocity Per Band",
       caption=fig2aCap)+
  theme(plot.caption=element_text(hjust=0,face="italic"))


```

For evaluating testing performance, we consider 3 separate metrics. 1)
The average absolute deviation from the correct velocity, 2) The % of
throws in which the wall was hit with the correct velocity and 3) The
average x velocity produced.

As is reflected in Results Figure 2B, the constant group performed
significantly better than the varied group at the 3 testing bands of
greatest interest. Both groups tended to perform worse for testing bands
further away from their training conditions. The varied group had a
slight advantage for bands 1000-1200 and 1200-1400, which were repeats
from training for the varied participants, but novel for the constant
participants.

### Modeling {.tabset}

In project 1, we applied model-based techniques to quantify and control
for the similarity between training and testing experience, which in
turn enabled us to account for the difference between varied and
constant training via an extended version of a similarity based
generalization model. In project 2, we will go a step further,
implementing a full process model capable of both 1) producing novel
responses and 2) modeling behavior in both the learning and testing
stages of the experiment. For this purpose, we will apply the
associative learning model (ALM) and the EXAM model of function learning
(DeLosh 1997). ALM is a simple connectionist learning model which
closely resembles Kruschke's ALCOVE model (Kruscke 1992), with
modifications to allow for the generation of continuous responses.

[ALM & Exam Description]{.underline} [@deloshExtrapolationSineQua1997]
Delosh et al. (1997) Could not export bibliography: no selection
introduced the associative learning model (ALM), a connectionist model
within the popular class of radial-basis networks. ALM was inspired by,
and closely resembles Kruschke's influential ALCOVE model of
categorization (Kruscke 1992). ALM is structured with input and output
nodes that correspond to regions of the stimulus space, and response
space, respectively. The units in the input layer activate as a function
of their similarity to a presented stimulus. As was the case with the
exemplar-based models, similarity in ALM is exponentially decaying
function of distance. So, for example, an input stimulus of value 55
would induce maximal activation of the input unit tuned to 55. Depending
on the value of the generalization parameter, the nearby units (e.g. 54
and 56; 53 and 57) may also activate to some degree. The input layer is
fully connected to the output layer, and the activation for any
particular output node is simply the weighted sum of the connection
weights between that node and the input activations. The network then
produces a response by taking the weighted average of the output units
(recall that each output unit has a value corresponding to a particular
response). During training, the network receives feedback which
activates each output unit as a function of its distance from the ideal
level of activation necessary to produce the correct response. The
connection weights between input and output units are then updated via
the standard delta learning rule, where the magnitude of weight changes
are controlled by a learning rate parameter.

See Table 2A for a full specification of the equations that define ALM
and EXAM.

[Model Fitting and Comparison]{.underline}

Following the procedure used by McDaniel & Busemeyer (2009), we will
assess the ability of both ALM and EXAM to account for the empirical
data when fitting the models to 1) only the training data, and 2) both
training and testing data. Models will be fit directly to the trial by
trial data of each individual participants, both by minimizing the
root-mean squared deviation (RMSE), and by maximizing log likelihood.

Finding the sensitivity and learning rate parameters most likely to have
generated the training data from a given participant. Each set of
parameter values results in a learning trajectory that produces a weight
matrix.

```{r echo=FALSE}

text_tbl <- data.frame(
    'Step'=c("Input Activation","Output Activation","Output Probability","Mean Output","Feedback Activation","Update Weights","Extrapolation",""),
    'Equation' = c("$a_i$(X) = $\\frac{e^{-c \\cdot (X-X_i)^2}}{ \\sum_{k=1}^Me^{-c \\cdot (X-X_i)^2}}$", 
                   '$O_j$(X) = $\\sum_{k=1}^Mw_{ji} \\cdot a_i(X)$',
                   '$P[Y_j | X] = \\frac{O_i(X)}{\\sum_{k=1}^Mo_k(X)}$',
                   "$m(x) = \\sum_{j=1}^LY_j \\cdot \\bigg[\\frac{O_j(X)}{\\sum_{k=1}^Lo_k(X)}\\bigg]$",
                   "$f_j(Z)=e^{-c\\cdot(Z-Y_j)^2}$",
                   "$w_{ji}(t+1)=w_{ji}(t)+\\alpha \\cdot {f_i(Z(t))-O_j(X(t))} \\cdot a_i(X(t))$",
                   "$P[X_i|X] = \\frac{a_i(X)}{\\sum_{k=1}^Ma_k(X)}$",
                   "$E[Y|X_i]=m(X_i) + \\bigg[\\frac{m(X_{i+1})-m(X_{i-1})}{X_{i+1} - X_{i-1}} \\bigg] \\cdot[X-X_i]$"),
    
    'Description'= c(
            "Activation of each input node, $X_i$, is a function of the Gaussian similarity between the node value and stimulus X. ",
            "Activation of each Output unit $O_j$ is the weighted sum of the input activations and association weights",
            "Each output node has associated response, $Y_j$. The probability of response $Y_j$ is determined by the ratio of output activations",
            "The response to stimulus x is the weighted average of the response probabilities",
            "After responding, feedback signal Z is presented, activating each output node via the Gaussian similarity to the ideal response  ",
            "Delta rule to update weights. Magnitude of weight changes controlled by learning rate parameter alpha.",
            "Novel test stimulus X activates input nodes associated with trained stimuli",
            "Slope value computed from nearest training instances and then added to the response associated with the nearest training instance,m(x)")
)
text_tbl$Step=cell_spec(text_tbl$Step,font_size=12)
text_tbl$Equation=cell_spec(text_tbl$Equation,font_size=20)
almTable=kable(text_tbl, 'html', 
  booktabs=T, escape = F, align='l',
  caption = '<span style = "color:black;"><center><strong>Table 2A: ALM & EXAM Equations</strong></center></span>',
  col.names=c("","Equation","Description")) %>%
  kable_styling(position="left",bootstrap_options = c("hover")) %>%
  column_spec(1, bold = F,border_right=T) %>%
  column_spec(2, width = '10cm')%>%
  column_spec(3, width = '15cm') %>%
  pack_rows("ALM Activation & Response",1,4,bold=FALSE,italic=TRUE) %>%
  pack_rows("ALM Learning",5,6,bold=FALSE,italic=TRUE) %>%
  pack_rows("EXAM",7,8,bold=FALSE,italic=TRUE) 
  #save_kable(file="almTable.html",self_contained=T)
almTable



```



## Project 3 {.tabset}

**The Influence of Variability in a Speeded Attentional-Control Task**

### Background {.tabset}

Last year, we applied to access data generated from the many popular
online games by Lumos Labs (Lumosity). We received access to data from
"Lost in Migration" a gamified version of the Eriksen Flanker task.
Users are presented with a configuration of 5 "birds" - a central
"target" bird and 4 "flanker" birds. The task is to indicate the
direction of the central bird as fast as possible using the
up/down/right/left arrow keys on their device. On 50% of trials, the
flanker birds are pointing the same direction as the target birds, while
on the other half of trials the flanker birds point in an incompatible
direction.

The total dataset consists of 8,551 individual users, 168,307 game
sessions, and 8,207,980 trials of the game. A subset of the users in the
dataset participated in a "split-test" conducted by Lumos Labs, wherein
new users could be randomly assigned to one of several modified version
of the game. The modified versions all increased the range of possible
values for up to 3 aspects of the task stimuli:

1)  The rotation of the flanker birds relative to the target on
    incongruent trials (90,180,270 in standard version, continuous range
    in modified version)

2)  The distance between flankers and target (constant in standard
    version),

3)  The size of the stimuli (constant in standard version)

**Figure 3A**

### Model-based analysis 1 {.tabset}

**Effect of split-test variability manipulation on learning** 1)
Residual Effect of Split-testvariation

-   After split-test users return to the standard version of LIM, for
    how long will we be able to detect behavioral differences between
    split-test and standard-only users (in terms of games and/or
    trials).

2)  Between-Group comparisons

-Standard version users vs. split test users during 'training' (Figure
3D)

-Standard vs. split-test on the first game after split test users switch
to standard version

o  Interaction with how many games split test users completed before
switching

-Higher varied vs. lower varied split test users

o  E.g'Flanker Size' users vs. 'Flanker Size & Rotation & Distance'
users.

### Model-based analysis 2 {.tabset}

**Trial-by-trial influence of repetition and variability** Like many
in-lab experiments, the LIM trials are randomized. A consequence of this
randomization is that some users will experience a greater proportion of
repeat trials, while others.

Trial-by-trial variability

-   The total \# of unique configurations experienced

-   The distance between trials - in terms of properties of stimuli
(number, arrangement)

- Distance between a new trial, and all of the previously experienced
trials (or some window).



## General Discussion {.tabset}


## References {.tabset}
