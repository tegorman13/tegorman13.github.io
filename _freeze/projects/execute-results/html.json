{
  "hash": "c58cfa6573b74bf7b8a8f278ca926584",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Projects\"\ndate: last-modified\n---\n\n\n\n\n\n\n# Labs & Collaborators \n\nRob Goldstone - [Percepts and Concepts Lab](https://pc.cogs.indiana.edu/)\n\nRob Nosofsky - [Nosofsky Lab](https://nosofsky.cogs.indiana.edu/)\n\nChen Yu - [Developmental Intelligence Lab](https://www.la.utexas.edu/users/dil/)\n\nC. Shawn Green - [Learning and Transfer Lab](https://greenlab.psych.wisc.edu/)\n\n\n_______________________________________________________________\n\n\n\n\n\n\n\n\n# Primary PhD Work\n\n<br>\n<br>\n<br>\n\n\n## Dissertation - The Role of Variability in Learning Generalization: A Computational Modeling Approa\n\n[Link to my dissertation website](https://tegorman13.github.io/Dissertation/paper.html)\n\n<br>\n\n## Variability and Visuomotor Learning\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](projects_files/figure-html/unnamed-chunk-2-1.png){width=480}\n:::\n:::\n\n\n\n\nFor this project, I programmed a simple projectile launching task to serve as a conceptual replication of an influential paradigm in the visuomotor skill learning literature. Several of the canonical empirical patterns are replicated, with the varied trained participants tending to perform better during testing in both experiments. A major issue with previous research in the cross-disciplinary \"benefits of variability\" literature is that many previous works do not adequately control for the similarity between training and testing conditions. Such issues arise when both from failures to consider the possibility of non-linear generalization, and from often the unquestioned assumption that participants are acquiring, and then generalizing from prototype or schema-based representations. I introduce a theoretically motivated method of explicitly quantifying the similarity between training experience and testing condition. The resulting similarity quantity can then be used to explicitly control for similarity (by adding it as a covariate to the statistical model). The effect of variability remains significant while controlling for similarity, which I argue is a more rigorous demonstration of the effect of variability on testing performance than what is typically provided with standard methods. I conclude by introducing an extended version of the model that assumes training variation influences the steepness of the generalization gradient. With this flexible similarity mechanism, the group-level effect of variability can then be accounted for within the similarity-based generalization framework.\\\n\n<br>\n\n[pdf of the journal article](https://tegorman13.github.io/pdf/Gorman_Goldstone_2022_Instance-based_model_varied_practice.pdf){target=\"_blank\"}\\\n[Link to online version of journal\narticle](https://www.sciencedirect.com/science/article/abs/pii/S0010028522000299){target=\"_blank\"}\n\n<br>\n\n## Examining the Effects of Training Variability on Extrapolation Performance\n\n<br>\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](projects_files/figure-html/unnamed-chunk-3-1.png){width=480}\n:::\n:::\n\n\n\n\nThis project investigates the influence of training variability on extrapolation in a uni-dimensional visuomotor function learning task. Across three experiments,  we compare constant and varied training  conditions in terms of learning performance, extrapolation accuracy, and the ability to reliably discriminate between stimuli. \n\nTo account for the empirical results, I fit the Associative Learning Model (ALM) and the Extrapolation-Association Model (EXAM) to the data from each individual participant. Notably, this study is the first to employ approximate Bayesian computation (ABC) to fit ALM and EXAM, enabling us to thoroughly investigate the full range of posterior predictions of each model, and to  examine the ability of these influential models of function learning to account for both the group level and individual level data.\n\n<br>\n\n[Link to project page](https://tegorman13.github.io/htw/){target=\"_blank\"} \\\n\n<br>\n\n## Investigating the Role of Variability in Real-World Learning\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](projects_files/figure-html/unnamed-chunk-4-1.png){width=480}\n:::\n:::\n\n\n\n\nThis project takes advantage of a large dataset from Lost In Migration, a popular online game resembling the classic Eriksen flanker task. Due to randomization of game trials, some users experience much more variability in the early phases of the game than others. Additionally, the dataset provided by Lumos labs includes data from users who experienced a 'high variability' version of the game before being switched to the standard version. I will assess the influence of both variability-via-randomization, and variability-via-manipulation, and once again evaluate the ability of similarity-based-generalization models to account for the observed patterns. While the key theoretical questions, and general modeling approach will remain the same as the first two projects, the Lost In Migration's dataset will present the opportunity to examine the influence of variability in a much more graded fashion, and to assess the ecological validity of the phenomena.\n\n<br>\n\n\n## Other Projects\n\\\n\n### Human perception of dot pattern prototype similarity\n\n  - In colloboration with Rob Nosofsky\n  - [Link to project site](https://tegorman13.github.io/dot_variability/)\n\n### Learning the Structure of the Environment\n\\\n- assessing how the properties of simple grid world environments influence how participants search for rewards\n\n### Effect of Distance and Sequence in Category Learning\n\n  -  In Colloboration with [Bradley Rogers](https://www.linkedin.com/in/bradley-rogers-b618294)\n  - Presented at MathPsych/ICCM Conference (2018)\n\\\n\n### Skewed vs. Uniform Frequency Distributions in Cross-Situational Learning\n- Collobration with Chen Yu\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}